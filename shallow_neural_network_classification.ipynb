{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "dfc28329-ab4f-4ada-a2bd-35450a72bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import copy\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a09988-f3d4-446b-a0c3-67dadf381ab6",
   "metadata": {},
   "source": [
    "## Initilizing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e5814eaf-3d60-4e6a-b34b-e496e5936530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of input layer\n",
    "    n_h -- size of hidden layer\n",
    "    n_y -- size of output layer\n",
    "    \"\"\"\n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        \"W1\":W1,\n",
    "        \"b1\":b1,\n",
    "        \"W2\":W2,\n",
    "        \"b2\":b2\n",
    "    }\n",
    "    return parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b69ae5-3130-4e54-9d36-00d20ae5da49",
   "metadata": {},
   "source": [
    "## Linear forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c52d8ea0-57ce-4881-add2-558c86c59e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A -- Activations from previous layer's (or input data)\n",
    "    W -- weights matrix\n",
    "    b -- bias vector\n",
    "    \"\"\"\n",
    "\n",
    "    Z = np.dot(W, A)+b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dd1ff-7177-4b35-a769-a8418477265c",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "31b04766-f0df-4fd4-8b20-e1e4af93c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Z -- value of linear function\n",
    "    \"\"\"\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, Z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8bb50-f105-43fa-93a7-5c74f7f338a5",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "21d7f1bb-ff41-45fe-bcc1-a561f47bb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605ab5b-473a-4e20-93f1-5299bb9d2ebe",
   "metadata": {},
   "source": [
    "## Linear activation forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "df6bff79-d737-435d-9bda-dd1e9aa82495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- actiations from previous layer (or input data)\n",
    "    W -- Weights matrix\n",
    "    b -- bias vector\n",
    "    \"\"\"\n",
    "    Z , linear_cache = linear_forward(A_prev, W, b)\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "22c2491c-13ad-4b98-a82f-1831db0460c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)//2\n",
    "    for l in range(1, L):\n",
    "        A, cache = linear_activation_forward(A, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b071750-afca-404a-894e-92d1c3a8d761",
   "metadata": {},
   "source": [
    "## computing cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c9b5a6bb-f8a6-41ab-8d3a-b52d75cf5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    AL -- probability vectr corresponding to label prediction\n",
    "    Y -- ground truth labels\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = -1/m * np.sum(Y*np.log(AL) + (1-Y)*np.log(1-AL))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45bf72-cbd5-4968-b0ce-3a952b30f21d",
   "metadata": {},
   "source": [
    "## Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c93c6571-8f2c-4548-b77a-0dcfdfb50904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1/m * np.dot(dZ, A_prev.T)\n",
    "    db = 1/m * np.sum(dZ, axis = 1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "44d4567c-bdb4-4e75-9cd5-cb0bea166172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ =dA* s*(1-s)\n",
    "    return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9da74def-9dba-4952-86e7-5a12b01ea6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z<=0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0736d51f-0c0a-4785-994b-6e75f6da7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache , activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "55c407c9-63b1-4a40-8aba-3c02273e97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = Y.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    dAL =-(np.divide(Y,AL) - np.divide(1-Y, 1-AL))\n",
    "    current_cache = caches[L-1]\n",
    "    dA_prev, dW, db = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    grads[\"dA\"+str(L-1)] = dA_prev\n",
    "    grads[\"dW\"+str(L)] = dW\n",
    "    grads[\"db\"+str(L)] = db\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache, \"relu\")\n",
    "        grads[\"dA\"+str(l)] = dA_prev\n",
    "        grads[\"dW\"+str(l+1)] = dW\n",
    "        grads[\"db\"+str(l+1)] = db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa47507-9eac-4c25-9918-c046a7edbc36",
   "metadata": {},
   "source": [
    "## Updating parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c036092a-86fe-40fc-8126-5f0f2c3a2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(grads, params, learning_rate):\n",
    "    parameters = copy.deepcopy(params)\n",
    "    L = len(parameters) //2\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "        parameters[\"W\"+str(l)] -= learning_rate*grads[\"dW\"+str(l)]\n",
    "        parameters[\"b\"+str(l)] -= learning_rate*grads[\"db\"+str(l)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c7837-0781-43d6-be5c-c377310a06fc",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "377ec82f-43f1-40dc-ab4d-a79b842104bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "21aba4d9-8864-440b-a9fd-d5fd3399c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3dd5f-f95b-4605-ad10-e91e3f9dfb87",
   "metadata": {},
   "source": [
    "### Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0bf4d0c2-f617-46ad-9a19-a471fd1982df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0],-1).T\n",
    "\n",
    "train_x = train_x_flatten/255\n",
    "test_x = test_x_flatten/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9a83c379-d083-4979-bb8a-24f9ba6d61fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (12288, 209)\n",
      "test_x shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x shape: \"+ str(train_x.shape))\n",
    "print(\"test_x shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ff91b-db39-4232-9ce1-4112406be5b7",
   "metadata": {},
   "source": [
    "## Shallow Neural Network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d708dfab-21fa-4541-8116-b23da3b0850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layer_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost =False):\n",
    "    grads = {}\n",
    "    costs = []\n",
    "    m = X.shape[1]\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    for i in range(0,num_iterations):\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        # print(A2, Y)\n",
    "\n",
    "        cost = compute_cost(A2, Y)\n",
    "\n",
    "        dA2 = -(np.divide(Y,A2)-np.divide(1-Y, 1-A2))\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        parameters = update_params(grads, parameters, learning_rate)\n",
    "\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "\n",
    "        if print_cost and i%100 == 0 or i == num_iterations-1:\n",
    "            print(f\"Cost after iteration {i}: {np.squeeze(cost)}\")\n",
    "        if i%100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "\n",
    "    return parameters, costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f102e53a-9006-403a-953d-9961bf851822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1: 0.6956426953726766\n"
     ]
    }
   ],
   "source": [
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)\n",
    "learning_rate = 0.0075\n",
    "parameters, costs = model(train_x, train_y, layers_dims , num_iterations = 2, print_cost=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "72b7aea4-e93a-4594-a982-fc2a5a6991b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6938297273399021\n",
      "Cost after iteration 100: 0.6452166905106488\n",
      "Cost after iteration 200: 0.6298768442088895\n",
      "Cost after iteration 300: 0.5985194571901594\n",
      "Cost after iteration 400: 0.5562825376952595\n",
      "Cost after iteration 500: 0.5134682148083451\n",
      "Cost after iteration 600: 0.4707001774665278\n",
      "Cost after iteration 700: 0.43608068719484455\n",
      "Cost after iteration 800: 0.3847543448592997\n",
      "Cost after iteration 900: 0.3457626961164924\n",
      "Cost after iteration 1000: 0.31677386925178475\n",
      "Cost after iteration 1100: 0.27151084043170026\n",
      "Cost after iteration 1200: 0.21456995657092695\n",
      "Cost after iteration 1300: 0.19736129691940543\n",
      "Cost after iteration 1400: 0.16644129915952688\n",
      "Cost after iteration 1500: 0.1487234117038711\n",
      "Cost after iteration 1600: 0.11606507583679075\n",
      "Cost after iteration 1700: 0.10278373763116644\n",
      "Cost after iteration 1800: 0.08262331630403412\n",
      "Cost after iteration 1900: 0.06784743969578055\n",
      "Cost after iteration 2000: 0.05730090490167227\n",
      "Cost after iteration 2100: 0.05007601826367886\n",
      "Cost after iteration 2200: 0.0440763572218261\n",
      "Cost after iteration 2300: 0.039311341183733396\n",
      "Cost after iteration 2400: 0.03519310535829778\n",
      "Cost after iteration 2499: 0.032056948341019076\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost=True)\n",
    "# plot_costs(costs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ec5edd9d-2333-476c-af70-a04558bcd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob, caches = L_model_forward(train_x, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "27ad877f-a2a1-42a1-b72b-9552d107e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, prob.shape[1]):\n",
    "    if prob[0,i]>0.5:\n",
    "        prob[0,i] = 1\n",
    "    else:\n",
    "        prob[0,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "aba02387-86c5-4ea0-8b22-490dfa1726d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3482b534-6ad5-45bd-9bae-80a183f08f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set is :0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on train set is :{np.sum((prob==train_y)/train_x.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cd549267-41ff-40c8-8231-672b94650cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test, caches = L_model_forward(test_x, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b4a72015-73fd-46c4-ac72-83fef925b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, prob_test.shape[1]):\n",
    "    if prob_test[0,i]>0.5:\n",
    "        prob_test[0,i] = 1\n",
    "    else:\n",
    "        prob_test[0,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1dae189e-687c-4991-aa2e-6c867cff1e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        1., 0.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1620b976-e2a1-4a10-a65e-94ad9f96c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 0.74\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test set is {np.sum((prob_test==test_y)/test_x.shape[1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32982bb4-a14a-4e31-9c6f-c0cc8f937c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
